# StoryTeller

This project uses AI to generate a story, extract characters and scenes, and then generate images for them.

## How to Run

1.  **Set up the environment:**
    *   Create a `.env` file in the root of the `StoryTeller` directory.
    *   Inside the `.env` file, add your Google API key like this:
        ```
        GOOGLE_API_KEY=your_api_key
        ```
2.  **Install dependencies:**
    *   Open your terminal and navigate to the `scripts` directory.
    *   Run the following command:
        ```
        pip install -r requirements.txt
        ```

3.  **Run the main script:**
    *   Open your terminal and navigate to the `scripts` directory.
    *   Run the following command:
        ```
        python main.py
        ```

## How to Play with Prompts

You can modify the prompts in the `prompts.py` file to change the generated story, characters, and images.

*   `STORY_GENERATION_PROMPT`: Change this prompt to generate a different story.
*   `CHARACTER_EXTRACTION_PROMPT`: You can modify this prompt to change how characters are extracted from the story.
*   `SCENE_EXTRACTION_PROMPT`: This prompt controls how scenes are extracted from the story. You can change it to get more or fewer scenes, or to change the level of detail in the scene descriptions.
*   `CHARACTER_IMAGE_PROMPT`: This prompt is used to generate images for the characters. You can add more details to the prompt to get more specific images.
*   `SCENE_IMAGE_PROMPT`: This prompt is used to generate images for the scenes. You can modify it to change the style or composition of the images.

## File Functionality

### `main.py`

This is the main script that runs the entire pipeline. It calls the other scripts in the following order:

1.  `generate_story.py`
2.  `generate_scenes.py`
3.  `generate_character_images.py`
4.  `generate_scene_images.py`

### `generate_story.py`

*   **What it does:** This script generates a story based on the `STORY_GENERATION_PROMPT` in `prompts.py`. It then extracts the characters from the story using the `CHARACTER_EXTRACTION_PROMPT` and saves them to `json_files/characters.json`.
*   **Prompt Engineering:** The `STORY_GENERATION_PROMPT` is a simple prompt that asks the model to write a short story. The `CHARACTER_EXTRACTION_PROMPT` is a more complex prompt that asks the model to identify the main characters and provide a brief description of each. This is a form of information extraction, where we use the model to pull structured data from unstructured text.

### `generate_scenes.py`

*   **What it does:** This script takes the story generated by `generate_story.py` and extracts key scenes from it. It uses the `SCENE_EXTRACTION_PROMPT` to identify 3-5 key scenes that are suitable for illustration. The scenes are saved to `json_files/scenes.json`.
*   **Prompt Engineering:** The `SCENE_EXTRACTION_PROMPT` is another example of information extraction. It asks the model to identify key scenes and provide a description and a list of characters for each scene. This structured output is then used to generate images for each scene.

### `generate_character_images.py`

*   **What it does:** This script generates images for each character extracted by `generate_story.py`. It uses the `CHARACTER_IMAGE_PROMPT` to generate a portrait of each character. The images are saved in the `Image_generated` directory.
*   **Prompt Engineering:** The `CHARACTER_IMAGE_PROMPT` is a simple prompt that asks the model to generate a portrait of a character. It includes the character's name and description to ensure the image is consistent with the story. The prompt also includes the phrase "Consistent character design" to encourage the model to generate images that are stylistically similar.

### `generate_scene_images.py`

*   **What it does:** This script generates images for each scene extracted by `generate_scenes.py`. It uses the `SCENE_IMAGE_PROMPT` to generate an illustration of each scene. The images are saved in the `Scene_Images` directory.
*   **Prompt Engineering:** The `SCENE_IMAGE_PROMPT` is a more complex prompt that asks the model to illustrate a scene. It includes the scene description and a character reference image to ensure the characters in the scene are consistent with the character images generated by `generate_character_images.py`. This is a form of multi-modal prompting, where we use both text and images to guide the model's output.
